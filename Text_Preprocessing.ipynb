{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doE39w8wNDcZ",
        "outputId": "309ec703-bf30-446d-cc00-6fdeba148eb2"
      },
      "outputs": [],
      "source": [
        "# Colab setup (uncomment if running fresh)\n",
        "# !python -m pip install -U pip\n",
        "#pip install spacy==3.* transformers==4.* tokenizers==0.* sentencepiece==0.* beautifulsoup4==4.* lxml==5.* regex==2024.* unidecode==1.*\n",
        "\n",
        "# Download a small spaCy model (English)\n",
        "!#python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eono4RzKNgAq",
        "outputId": "1e6497a9-19f2-4ecf-90b6-dae8a1d472fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whitespace: ['I', \"can't\", 'believe', \"it's\", 'not', 'butter!', 'Visit', 'https://example.org,', 'or', 'email', 'info@example.com.']\n"
          ]
        }
      ],
      "source": [
        "#Classical tokenization\n",
        "import re\n",
        "\n",
        "text = \"I can't believe it's not butter! Visit https://example.org, or email info@example.com.\"\n",
        "\n",
        "# Whitespace-based tokens (baseline)\n",
        "ws_tokens = text.split()\n",
        "\n",
        "# Basic rule: split punctuation as separate tokens, keep contractions intact\n",
        "# rule_tokens = re.findall(r\"[A-Za-z]+(?:'[A-Za-z]+)?|[0-9]+|[^\\sA-Za-z0-9]\", text)\n",
        "\n",
        "print(\"Whitespace:\", ws_tokens)\n",
        "# print(\"Rule-based:\", rule_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSaOrEMBNpDP"
      },
      "outputs": [],
      "source": [
        "# Compare tokenizers (spaCy, BERT, GPT-2, T5)\n",
        "import spacy\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "text = \"I can’t believe it’s not butter!\"  # note: curly apostrophes\n",
        "\n",
        "# spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "spacy_toks = [t.text for t in nlp(text)]\n",
        "\n",
        "# BERT (WordPiece)\n",
        "bert_tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_toks = bert_tok.convert_ids_to_tokens(bert_tok.encode(text, add_special_tokens=False))\n",
        "\n",
        "# GPT-2 (byte-level BPE)\n",
        "gpt2_tok = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "gpt2_toks = gpt2_tok.convert_ids_to_tokens(gpt2_tok.encode(text, add_special_tokens=False))\n",
        "\n",
        "# T5 (SentencePiece / Unigram LM)\n",
        "t5_tok = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "t5_toks = t5_tok.convert_ids_to_tokens(t5_tok.encode(text, add_special_tokens=False))\n",
        "\n",
        "print(\"spaCy:\", spacy_toks)\n",
        "print(\"BERT:\", bert_toks)\n",
        "print(\"GPT-2:\", gpt2_toks)\n",
        "print(\"T5:\", t5_toks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeudAEbzk3Q8",
        "outputId": "b23dc00a-6d0b-4f91-fcf0-749dc6532250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'just', 'bought', 'my', 'apple', 'watch', '!']\n"
          ]
        }
      ],
      "source": [
        "bert_toks2 = bert_tok.convert_ids_to_tokens(bert_tok.encode(\"I just bought my Apple watch!\", add_special_tokens=False))\n",
        "print(bert_toks2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY6_TtGvNt1s",
        "outputId": "fc3d148a-ee26-453f-c477-a031eec62cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'orig': 'café', 'NFC': 'café', 'NFD': 'café', 'NFKC': 'café', 'NFKD': 'café'}\n",
            "{'orig': 'café', 'NFC': 'café', 'NFD': 'café', 'NFKC': 'café', 'NFKD': 'café'}\n",
            "Equality (raw): False\n",
            "Equality (NFC): True\n"
          ]
        }
      ],
      "source": [
        "# Unicode normalization (NFC vs NFKC)\n",
        "import unicodedata\n",
        "\n",
        "s1 = \"café\"                     # composed: 'é' U+00E9\n",
        "s2 = \"cafe\\u0301\"               # decomposed: 'e' + COMBINING ACUTE\n",
        "\n",
        "def show_norm(s):\n",
        "    return {\n",
        "        \"orig\": s,\n",
        "        \"NFC\": unicodedata.normalize(\"NFC\", s),\n",
        "        \"NFD\": unicodedata.normalize(\"NFD\", s),\n",
        "        \"NFKC\": unicodedata.normalize(\"NFKC\", s),\n",
        "        \"NFKD\": unicodedata.normalize(\"NFKD\", s),\n",
        "    }\n",
        "\n",
        "print(show_norm(s1))\n",
        "print(show_norm(s2))\n",
        "\n",
        "print(\"Equality (raw):\", s1 == s2)\n",
        "print(\"Equality (NFC):\", unicodedata.normalize(\"NFC\", s1) == unicodedata.normalize(\"NFC\", s2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWYsVydzNxrC",
        "outputId": "b7f40fbb-adbc-401e-a269-ca1ddb8acb9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contact us at   ! Visit  or  our site .\n",
            " New iPhones!!!  Limited  stock. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Regex cleaning (remove emails/URLs/HTML)\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "raw = \"\"\"\n",
        "<p>Contact us at <b>info@example.com</b>! Visit https://example.org or <a href=\"https://example.com\">our site</a>.\n",
        "<div>New iPhones!!! <em>Limited</em> stock.</div>\n",
        "\"\"\"\n",
        "\n",
        "# Strip HTML tags (BeautifulSoup) → text only\n",
        "text = BeautifulSoup(raw, \"lxml\").get_text(separator=\" \")\n",
        "\n",
        "# # Remove emails and URLs\n",
        "text = re.sub(r\"\\S+@\\S+\\.\\S+\", \"\", text)            # emails\n",
        "text = re.sub(r\"http[s]?://\\S+\", \"\", text)          # urls\n",
        "\n",
        "# # Collapse extra whitespace\n",
        "# text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noo9hm37N2IM",
        "outputId": "e31d8962-9190-41ba-c3ce-0459e6dc2d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dates: ['2024-10-12', '2025-01-05']\n",
            "Ticket IDs: ['A-12345', 'B-987']\n"
          ]
        }
      ],
      "source": [
        "# Regex Extraction\n",
        "import re\n",
        "\n",
        "doc = \"Conference dates: 2024-10-12 and 2025-01-05. Ticket IDs: A-12345, B-987.\"\n",
        "dates = re.findall(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\", doc)\n",
        "ticket_ids = re.findall(r\"\\b[A-Z]-\\d{3,6}\\b\", doc)\n",
        "\n",
        "print(\"Dates:\", dates)\n",
        "print(\"Ticket IDs:\", ticket_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re2zF90BN2LE",
        "outputId": "fff1c523-ca83-4d06-9989-72567ca78ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: ['This', 'is', 'really', 'not', 'great', '!', '!', '!', 'Honestly', ',', 'I', '’m', 'shocked', '.']\n",
            "No stopwords: ['great', '!', '!', '!', 'Honestly', ',', 'shocked', '.']\n",
            "No punctuation: ['This', 'is', 'really', 'not', 'great', 'Honestly', 'I', '’m', 'shocked']\n",
            "Lemma+lower, no stop/punct: ['great', 'honestly', 'shocked']\n"
          ]
        }
      ],
      "source": [
        "# Stopwords & punctuation choices (spaCy)\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "sent = \"This is really not great!!! Honestly, I’m shocked.\"\n",
        "\n",
        "doc = nlp(sent)\n",
        "keep_all = [t.text for t in doc]\n",
        "no_stop = [t.text for t in doc if not t.is_stop]\n",
        "no_punct = [t.text for t in doc if not t.is_punct]\n",
        "lemma_lower_no_stop_punct = [t.lemma_.lower() for t in doc if not t.is_stop and not t.is_punct]\n",
        "\n",
        "print(\"Original:\", keep_all)\n",
        "print(\"No stopwords:\", no_stop)\n",
        "print(\"No punctuation:\", no_punct)\n",
        "print(\"Lemma+lower, no stop/punct:\", lemma_lower_no_stop_punct)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-ggm2BgN2ON",
        "outputId": "ac94cf30-611a-44ae-8089-ee72d04937d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'release', 'new', 'iphone', 'visit', 'detail']\n"
          ]
        }
      ],
      "source": [
        "# End-to-end preprocessing pipeline (spaCy + regex)\n",
        "import re, unicodedata, spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "URL_RE = re.compile(r\"http\\S+\")\n",
        "HTML_RE = re.compile(r\"<.*?>\", flags=re.S)\n",
        "\n",
        "def preprocess(text: str):\n",
        "    # 1) Unicode normalization (NFKC)\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "\n",
        "    # 2) Remove URLs & HTML\n",
        "    text = URL_RE.sub(\"\", text)\n",
        "    text = HTML_RE.sub(\"\", text)\n",
        "\n",
        "    # 3) spaCy processing\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # 4) Normalize: case-fold + lemmatize, filter stop/punct/space\n",
        "    out = []\n",
        "    for tok in doc:\n",
        "        if tok.is_stop or tok.is_punct or tok.is_space:\n",
        "            continue\n",
        "        lemma = tok.lemma_.lower().strip()\n",
        "        # if lemma: // may be necessary for large document\n",
        "        out.append(lemma)\n",
        "    return out\n",
        "\n",
        "sample = \"Apple is releasing the new iPhone!!! Visit https://apple.com for details.\"\n",
        "print(preprocess(sample))\n",
        "# Expected-style output: ['apple', 'release', 'new', 'iphone', 'visit', 'detail']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GFELMr0N2RV",
        "outputId": "e4a9b906-a755-4637-c4db-2d4761f61cd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAW: Apple is releasing the new iPhone!!! Visit https://apple.com for details.\n",
            "NFKC: Apple is releasing the new iPhone!!! Visit https://apple.com for details.\n",
            "CLEAN: Apple is releasing the new iPhone!!! Visit  for details.\n",
            "TOKENS: ['Apple', 'is', 'releasing', 'the', 'new', 'iPhone', '!', '!', '!', 'Visit', ' ', 'for', 'details', '.']\n",
            "LEMMA+FILTERED: ['apple', 'release', 'new', 'iphone', 'visit', 'detail']\n"
          ]
        }
      ],
      "source": [
        "# Tiny helper to show each pipeline stage\n",
        "def show_stages(text: str):\n",
        "    import re, unicodedata, spacy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    URL_RE = re.compile(r\"http\\S+\")\n",
        "    HTML_RE = re.compile(r\"<.*?>\", flags=re.S)\n",
        "\n",
        "    print(\"RAW:\", text)\n",
        "    t1 = unicodedata.normalize(\"NFKC\", text)\n",
        "    print(\"NFKC:\", t1)\n",
        "    t2 = URL_RE.sub(\"\", HTML_RE.sub(\"\", t1))\n",
        "    print(\"CLEAN:\", t2)\n",
        "    doc = nlp(t2)\n",
        "    print(\"TOKENS:\", [t.text for t in doc])\n",
        "    lemmas = [t.lemma_.lower() for t in doc if not (t.is_stop or t.is_punct or t.is_space)]\n",
        "    print(\"LEMMA+FILTERED:\", lemmas)\n",
        "\n",
        "show_stages(\"Apple is releasing the new iPhone!!! Visit https://apple.com for details.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HysLOKuOOsWQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CoRe6DJOsan"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
